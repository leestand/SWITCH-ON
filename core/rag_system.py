"""
RAG ì‹œìŠ¤í…œ í•µì‹¬ ë¡œì§
"""
import time
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_community.document_transformers import LongContextReorder
from langchain_core.documents import Document

from config.settings import (
    LEGAL_SIMILARITY_THRESHOLD, 
    NEWS_SIMILARITY_THRESHOLD, 
    MIN_RELEVANT_DOCS
)
from core.embeddings import OptimizedKoSBERTEmbeddings
from core.preprocessor import LegalQueryPreprocessor


class OptimizedConditionalRAGSystem:
    """ì „ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìµœì í™”ëœ ì¡°ê±´ë¶€ ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
    
    def __init__(self, legal_db_path, news_db_path, legal_collection, news_collection):
        print("ğŸš€ ìµœì í™”ëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        start_time = time.time()
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        print("ğŸ”„ ë²•ë¥  ìš©ì–´ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì¤‘...")
        self.query_preprocessor = LegalQueryPreprocessor()
        print("âœ… ë²•ë¥  ìš©ì–´ ì „ì²˜ë¦¬ê¸° ì¤€ë¹„ ì™„ë£Œ")
        
        # ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
        self.legal_embedding_function = OptimizedKoSBERTEmbeddings()
        print("ğŸ“Š ë²•ë¥  DBì™€ ë‰´ìŠ¤ DB ëª¨ë‘ KoSBERT 768ì°¨ì› ì„ë² ë”© ì‚¬ìš©")
        
        # ì„ê³„ê°’ ì„¤ì •
        self.legal_similarity_threshold = LEGAL_SIMILARITY_THRESHOLD
        self.news_similarity_threshold = NEWS_SIMILARITY_THRESHOLD
        self.min_relevant_docs = MIN_RELEVANT_DOCS
        
        # DB ì—°ê²° ìµœì í™”
        self._init_legal_db(legal_db_path, legal_collection)
        self._init_news_db(news_db_path, news_collection)
        
        init_time = time.time() - start_time
        print(f"âš¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}ì´ˆ)")
    
    def _init_legal_db(self, legal_db_path, legal_collection):
        """ë²•ë¥  DB ì´ˆê¸°í™” ìµœì í™”"""
        print(f"ğŸ›ï¸ ë²•ë¥  DB ì—°ê²° ì¤‘...")
        try:
            self.legal_db = Chroma(
                persist_directory=legal_db_path,
                collection_name=legal_collection,
                embedding_function=self.legal_embedding_function
            )
            
            self.legal_documents = None
            self.legal_bm25_retriever = None
            self.legal_hybrid_retriever = None
            
            self.legal_vector_retriever = self.legal_db.as_retriever(
                search_type="similarity", 
                search_kwargs={"k": 5}
            )
            print("âœ… ë²•ë¥  DB ì—°ê²° ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë²•ë¥  DB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.legal_db = None
            self.legal_vector_retriever = None
    
    def _init_news_db(self, news_db_path, news_collection):
        """ë‰´ìŠ¤ DB ì´ˆê¸°í™” ìµœì í™”"""
        print(f"ğŸ“° ë‰´ìŠ¤ DB ì—°ê²° ì¤‘...")
        try:
            self.news_db = Chroma(
                persist_directory=news_db_path,
                collection_name=news_collection,
                embedding_function=self.legal_embedding_function
            )
            
            news_count = self.news_db._collection.count()
            print(f"âœ… ë‰´ìŠ¤ DB ì—°ê²° ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {news_count})")
            
            try:
                test_docs = self.news_db.similarity_search("ì „ì„¸", k=1)
                print(f"ğŸ§ª ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_docs)}ê°œ")
                if test_docs:
                    print(f"   ìƒ˜í”Œ ì œëª©: {test_docs[0].metadata.get('title', 'ì œëª©ì—†ìŒ')[:50]}...")
            except Exception as test_e:
                print(f"âš ï¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_e}")
            
            self.news_vector_retriever = self.news_db.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 4}
            )
            
            print("âœ… ë‰´ìŠ¤ DB KoSBERT 768ì°¨ì› ì„ë² ë”© ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ DB ì—°ê²° ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            self.news_db = None
            self.news_vector_retriever = None
    
    def _lazy_init_hybrid_retriever(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì§€ì—° ì´ˆê¸°í™”"""
        if self.legal_hybrid_retriever is None and self.legal_db is not None:
            print("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì¤‘...")
            try:
                legal_data = self.legal_db.get()
                
                if not legal_data or not legal_data.get("documents"):
                    print("âš ï¸ ë²•ë¥  DBì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
                    return
                
                all_legal_docs = legal_data["documents"]
                all_legal_metadatas = legal_data.get("metadatas", [{}] * len(all_legal_docs))
                
                if len(all_legal_metadatas) < len(all_legal_docs):
                    all_legal_metadatas.extend([{}] * (len(all_legal_docs) - len(all_legal_metadatas)))
                
                self.legal_documents = [
                    Document(page_content=doc, metadata=meta or {})
                    for doc, meta in zip(all_legal_docs, all_legal_metadatas)
                ]
                
                print(f"ğŸ“„ ë²•ë¥  ë¬¸ì„œ ë¡œë”© ì™„ë£Œ: {len(self.legal_documents)}ê°œ")
                
                self.legal_bm25_retriever = BM25Retriever.from_documents(self.legal_documents)
                self.legal_bm25_retriever.k = 8
                
                self.legal_hybrid_retriever = EnsembleRetriever(
                    retrievers=[self.legal_vector_retriever, self.legal_bm25_retriever],
                    weights=[0.65, 0.35]
                )
                print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©: {e}")
                import traceback
                print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                self.legal_hybrid_retriever = None
    
    def calculate_cosine_similarity_score(self, query, docs, use_news_embedding=False):
        """ìµœì í™”ëœ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not docs:
            return 0.0
        
        try:
            query_embedding = self.legal_embedding_function.embed_query(query)
            
            if not isinstance(query_embedding, np.ndarray):
                query_embedding = np.array(query_embedding)
            
            if query_embedding.ndim > 1:
                query_embedding = query_embedding.flatten()
            
            limited_docs = docs[:5]
            doc_texts = [doc.page_content[:1500] for doc in limited_docs]
            
            doc_embeddings = self.legal_embedding_function.embed_documents(doc_texts)
            
            if not isinstance(doc_embeddings, np.ndarray):
                doc_embeddings = np.array(doc_embeddings)
            
            if doc_embeddings.ndim == 1:
                doc_embeddings = doc_embeddings.reshape(1, -1)
            
            if query_embedding.shape[0] != doc_embeddings.shape[1]:
                print(f"âš ï¸ ì°¨ì› ë¶ˆì¼ì¹˜: ì¿¼ë¦¬ {query_embedding.shape[0]}, ë¬¸ì„œ {doc_embeddings.shape[1]}")
                return 0.65
            
            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]
            
            return float(np.max(similarities)) if len(similarities) > 0 else 0.0
            
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.65
    
    def search_legal_db(self, query):
        """ìµœì í™”ëœ ë²•ë¥  DB ê²€ìƒ‰"""
        if self.legal_db is None:
            print("âŒ ë²•ë¥  DBê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return [], 0.0
        
        try:
            # ğŸ” ì¿¼ë¦¬ í™•ì¥ ì ìš©
            expanded_query = self._expand_query_with_legal_terms(query)
            if expanded_query != query:
                print(f"ğŸ”„ í™•ì¥ëœ ë²•ë¥  ê²€ìƒ‰ ì¿¼ë¦¬: {expanded_query}")
            else:
                print(f"ğŸ” ë²•ë¥  DB ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
            
            # í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
            legal_docs = self.legal_vector_retriever.invoke(expanded_query)
            print(f"ğŸ“„ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(legal_docs)}ê°œ ë¬¸ì„œ")
            
            if legal_docs:
                for i, doc in enumerate(legal_docs[:2]):
                    doc_type = doc.metadata.get('doc_type', 'ìœ í˜•ë¶ˆëª…')
                    content_preview = str(doc.page_content)[:50] if doc.page_content else "ë‚´ìš©ì—†ìŒ"
                    print(f"   [{i+1}] {doc_type}: {content_preview}...")
            else:
                print("   âš ï¸ ë²¡í„° ê²€ìƒ‰ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨")
            
            if len(legal_docs) < self.min_relevant_docs:
                print(f"ğŸ“Š ë¬¸ì„œ ê°œìˆ˜ ë¶€ì¡±({len(legal_docs)} < {self.min_relevant_docs}), í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œë„")
                self._lazy_init_hybrid_retriever()
                if self.legal_hybrid_retriever is not None:
                    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ë„ í™•ì¥ëœ ì¿¼ë¦¬ ì‚¬ìš©
                    hybrid_docs = self.legal_hybrid_retriever.invoke(expanded_query)
                    print(f"ğŸ“„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼: {len(hybrid_docs)}ê°œ ë¬¸ì„œ")
                    if len(hybrid_docs) > len(legal_docs):
                        legal_docs = hybrid_docs
                        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ë¡œ êµì²´")
            
            if len(legal_docs) > 5:
                legal_docs = LongContextReorder().transform_documents(legal_docs)
                print("ğŸ”„ ë¬¸ì„œ ì¬ì •ë ¬ ì™„ë£Œ")
            
            # ìœ ì‚¬ë„ ê³„ì‚°ì€ ì›ë³¸ ì¿¼ë¦¬ë¡œ (ë” ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´)
            similarity_score = self.calculate_cosine_similarity_score(query, legal_docs, use_news_embedding=False)
            print(f"ğŸ“Š ë²•ë¥  DB ìµœì¢… ì ìˆ˜: {similarity_score:.3f}")
            
            return legal_docs, similarity_score
            
        except Exception as e:
            print(f"âŒ ë²•ë¥  DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return [], 0.0
    
    def search_news_db(self, query):
        """ìµœì í™”ëœ ë‰´ìŠ¤ DB ê²€ìƒ‰"""
        if self.news_db is None or self.news_vector_retriever is None:
            print("âŒ ë‰´ìŠ¤ DBê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return [], 0.0
        
        try:
            enhanced_query = self._enhance_news_query(query)
            print(f"ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬: {enhanced_query}")
            
            news_docs = self.news_vector_retriever.invoke(enhanced_query)
            print(f"ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(news_docs)}ê°œ")
            
            if news_docs:
                for i, doc in enumerate(news_docs[:2]):
                    title = doc.metadata.get('title', 'ì œëª©ì—†ìŒ')
                    print(f"   [{i+1}] {title[:50]}...")
            else:
                print("   âš ï¸ ë‰´ìŠ¤ ê²€ìƒ‰ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨")
            
            if news_docs:
                similarity_score = self.calculate_cosine_similarity_score(
                    enhanced_query, news_docs, use_news_embedding=False
                )
                print(f"ğŸ“Š ë‰´ìŠ¤ ê²€ìƒ‰ ì ìˆ˜: {similarity_score:.3f}")
            else:
                similarity_score = 0.0
            
            return news_docs, similarity_score
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return [], 0.0
    
    def _expand_query_with_legal_terms(self, query):
        """ë²•ë¥  ì¿¼ë¦¬ í™•ì¥ - ë™ì˜ì–´ì™€ ê´€ë ¨ ìš©ì–´ ì¶”ê°€"""
        expansion_terms = []
        
        # ë¶€ë™ì‚° ê´€ë ¨ í™•ì¥
        if "ë³´ì¦ê¸ˆ" in query: 
            expansion_terms.extend(["ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ", "ì „ì„¸ê¸ˆ"])
        if "ì§‘ì£¼ì¸" in query: 
            expansion_terms.append("ì„ëŒ€ì¸")
        if "ì„¸ì…ì" in query: 
            expansion_terms.append("ì„ì°¨ì¸")
        if "ì›”ì„¸" in query:
            expansion_terms.append("ì°¨ì„")
        if "ê³„ì•½ì„œ" in query:
            expansion_terms.append("ì„ëŒ€ì°¨ê³„ì•½ì„œ")
        
        # ë²•ì  ì ˆì°¨ ê´€ë ¨ í™•ì¥
        if "ì†Œì†¡" in query:
            expansion_terms.extend(["ë¯¼ì‚¬ì†Œì†¡", "ì†Œì†¡ì ˆì°¨"])
        if "ì†í•´ë°°ìƒ" in query:
            expansion_terms.append("ë°°ìƒì²­êµ¬")
        if "ëª…ë„" in query:
            expansion_terms.extend(["ëª…ë„ì²­êµ¬", "í‡´ê±°"])
        
        # ì „ì„¸ì‚¬ê¸° ê´€ë ¨ í™•ì¥
        if any(term in query for term in ["ì‚¬ê¸°", "ê¹¡í†µì „ì„¸", "ì „ì„¸ì‚¬ê¸°"]):
            expansion_terms.extend(["ì „ì„¸ì‚¬ê¸°", "ì„ëŒ€ì°¨ì‚¬ê¸°", "ë³´ì¦ê¸ˆì‚¬ê¸°"])
        
        # ìµœëŒ€ 3ê°œ ìš©ì–´ë§Œ ì¶”ê°€ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ)
        if expansion_terms:
            unique_terms = list(set(expansion_terms))[:3]
            expanded_query = f"{query} {' '.join(unique_terms)}"
            return expanded_query
        
        return query
    
    def _enhance_news_query(self, query):
        """ë‰´ìŠ¤ ì¿¼ë¦¬ ê°•í™”"""
        # ê¸°ë³¸ ê°•í™”
        enhanced = query
        if any(term in query for term in ["ì „ì„¸", "ë¶€ë™ì‚°", "ì„ëŒ€", "ì‚¬ê¸°"]):
            enhanced = f"{query} ì „ì„¸ì‚¬ê¸°"
        
        return enhanced
    
    def conditional_retrieve(self, original_query):
        """ì¡°ê±´ë¶€ ê²€ìƒ‰ - ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì¶”ê°€"""
        try:
            print(f"ğŸ” ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬: {original_query}")
            
            # âœ… í•µì‹¬ ì¶”ê°€: ì¼ìƒì–´ â†’ ë²•ë¥ ì–´ ì „ì²˜ë¦¬
            converted_query, conversion_method = self.query_preprocessor.convert_query(original_query)
            
            if conversion_method != "no_conversion":
                print(f"ğŸ”„ ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {converted_query}")
                print(f"ğŸ“‹ ë³€í™˜ ë°©ë²•: {conversion_method}")
                # ì‹¤ì œ ê²€ìƒ‰ì—ëŠ” ë³€í™˜ëœ ì¿¼ë¦¬ ì‚¬ìš©
                search_query = converted_query
            else:
                print("ğŸ“‹ ì´ë¯¸ ë²•ë¥  ìš©ì–´ë¡œ êµ¬ì„±ëœ ì¿¼ë¦¬")
                search_query = original_query
            
            # 1ë‹¨ê³„: ë²•ë¥  DB ê²€ìƒ‰ (ë³€í™˜ëœ ì¿¼ë¦¬ ì‚¬ìš©)
            print("ğŸ›ï¸ ë²•ë¥  DB ê²€ìƒ‰ ì¤‘...")
            legal_docs, legal_score = self.search_legal_db(search_query)
            print(f"ğŸ“Š ë²•ë¥  DB ê²°ê³¼: {len(legal_docs)}ê°œ ë¬¸ì„œ, ì ìˆ˜: {legal_score:.3f}")
            
            # 2ë‹¨ê³„: ë²•ë¥  DB ê²°ê³¼ ì¶©ë¶„ì„± í‰ê°€
            is_legal_sufficient = (
                legal_score >= self.legal_similarity_threshold and 
                len(legal_docs) >= self.min_relevant_docs
            )
            
            if is_legal_sufficient:
                print("âœ… ë²•ë¥  DB ê²°ê³¼ë§Œìœ¼ë¡œ ì¶©ë¶„í•¨")
                return legal_docs, "legal_only"
            
            # 3ë‹¨ê³„: ë²•ë¥  DB ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ ë‰´ìŠ¤ DB ê²€ìƒ‰
            print("ğŸ“° ë²•ë¥  DB ê²°ê³¼ ë¶€ì¡±, ë‰´ìŠ¤ DBë¡œ ë³´ì™„ ê²€ìƒ‰...")
            news_docs, news_score = self.search_news_db(search_query)
            print(f"ğŸ“Š ë‰´ìŠ¤ DB ê²°ê³¼: {len(news_docs)}ê°œ ë¬¸ì„œ, ì ìˆ˜: {news_score:.3f}")
            
            # 4ë‹¨ê³„: ê²°ê³¼ ê²°í•©
            combined_docs = []
            
            if legal_docs:
                combined_docs.extend(legal_docs[:8])  # ë²•ë¥  ë¬¸ì„œ ìµœëŒ€ 8ê°œë¡œ ì¦ê°€
                print(f"âœ… ë²•ë¥  ë¬¸ì„œ {len(legal_docs[:8])}ê°œ ì¶”ê°€")
            
            if news_docs and news_score >= self.news_similarity_threshold:
                combined_docs.extend(news_docs[:3])  # ë‰´ìŠ¤ëŠ” 3ê°œë¡œ ì¡°ì • (ì´ 11ê°œ ë°©ì§€)
                print(f"âœ… ë‰´ìŠ¤ ë¬¸ì„œ {len(news_docs[:5])}ê°œ ì¶”ê°€")
                search_type = "legal_and_news"
            elif legal_docs:
                search_type = "legal_only"
            else:
                search_type = "no_results"
            
            print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {len(combined_docs)}ê°œ ë¬¸ì„œ ({search_type})")
            return combined_docs, search_type
                
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return [], "error"
